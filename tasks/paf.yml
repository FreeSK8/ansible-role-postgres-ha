# vim: set filetype=yaml expandtab tabstop=2 shiftwidth=2 softtabstop=2 background=dark :

- name: select proper PAF package (centos7)
  set_fact:
    paf_pkg: 'resource-agents-paf-{{ postgres_ha_paf_version }}-1.noarch.rpm'
  when: os_version == 'centos7'

- name: select proper PAF package (centos6)
  set_fact:
    paf_pkg: 'resource-agents-paf-1.1.0-1.noarch.rpm'
  when: os_version == 'centos6'

# this rpm is also available on github.. but when multiple servers start to download 
# the same file from github simultanneously, github will likely block you
# and the role will fail
# that's why it's embedded in the role

- name: copy PAF rpm to hosts
  copy: src="{{ paf_pkg }}" dest="/tmp/{{ paf_pkg }}"
  when: os_version != 'ubuntu20'

- name: install PAF DB failover agent
  yum:
    name: "/tmp/{{ paf_pkg }}"
    state: present
  when: os_version != 'ubuntu20'

- name: install PAF ubuntu
  apt:
    name: resource-agents-paf
    state: present
  when: os_version == 'ubuntu20'

- name: install latest PAF 2.3.0 monitor perl script
  copy:
    src: 'pgsqlms-PAF23'
    dest: '/usr/lib/ocf/resource.d/heartbeat/pgsqlms'
  args:
    owner: root
    group: root
    mode:  0555
  when: postgres_ha_paf_version == '2.3.0'

#- name: apply PAF v2.2.0 fix for newest pacemaker
#  copy:
#    src: 'pgsqlms-2.2.0-fix-pg10'
#    dest: '/usr/lib/ocf/resource.d/heartbeat/pgsqlms'
#  args:
#    owner: root
#    group: root
#    mode:  0555
#  when: postgres_ha_paf_version == '2.2.0' and
#        not postgres_ha_paf_geo_patch

- name: apply geo-HA patches to DB failover agent
  copy:
    src: 'pgsqlms-{{ postgres_ha_paf_version }}-geo-patched'
    dest: '/usr/lib/ocf/resource.d/heartbeat/pgsqlms'
  args:
    owner: root
    group: root
    mode:  0555
  when: postgres_ha_paf_geo_patch

- name: prepare DB recovery config
  template: src=recovery.conf.pcmk.j2 dest="{{ postgres_ha_pg_data }}/../recovery.conf.{{postgres_ha_cluster_name}}.pcmk"
  args:
    owner: postgres
    group: postgres
    mode:  0644
  when: postgres_ha_pg_version < 12

- name: prepare DB recovery config for 12+
  lineinfile: dest=/etc/postgresql/12/main/postgresql.conf regexp='^primary_conninfo =' line="primary_conninfo = 'port={{ postgres_ha_pg_port }} host={{ postgres_ha_cluster_vip }} application_name={{ inventory_hostname }} user={{ postgres_ha_pg_repl_user }} '" state=present
  when: postgres_ha_pg_version >= 12

- name: prepare DB recovery config for 12+
  lineinfile: dest=/etc/postgresql/12/main/postgresql.conf regexp='^recovery_target_timeline =' line="recovery_target_timeline = 'latest'" state=present
  when: postgres_ha_pg_version >= 12

- name: stop database for clustering
  service: name="{{ postgres_ha_pg_systemd_svcname }}" state=stopped enabled=false

- name: remove default PGSQL generated auto.conf that came with the apt install earlier
  file:
    path: /var/lib/postgresql/12/main/postgresql.auto.conf
    state: absent

- name: create database cluster resource
  when: inventory_hostname == postgres_ha_cluster_master_host    # run only on one node
  pcs_resource:
    name: "{{ postgres_ha_cluster_pg_HA_res_name }}"    # master resource name
    child_name: "{{ postgres_ha_cluster_pg_res_name }}" #  slave resource name
    resource_class: 'promotable'
    resource_type: ocf:heartbeat:pgsqlms
    force_resource_update: true
    options: >
      {% if db_resource_exists is not succeeded %}--disabled{% endif %}
      bindir="{{ postgres_ha_pg_bindir }}"
      pgdata="{{ postgres_ha_pg_data }}"
      pgport="{{ postgres_ha_pg_port }}"
      start_opts="-c config_file=/etc/postgresql/12/main/postgresql.conf"
      pghost=/var/run/postgresql
      op start timeout=60s
      op stop timeout=60s
      op promote timeout=30s
      op demote timeout=120s
      op notify timeout=60s
      op monitor interval="{{ postgres_ha_monitor_interval_pgmaster }}" timeout=10s role="Master"
      op monitor interval="{{ postgres_ha_monitor_interval_pgslave }}"  timeout=10s role="Slave"
      meta notify=true master-max=1 master-node-max=1 clone-max="{{ ansible_play_batch|length }}" clone-node-max=1
      promotable notify=true
